# Learning Log 4
![Ready Trader Go](/assets/images/ready-trader-go.jpg)

## Current goals
- Improve the computational efficiency of the autotrader program with a view to increasing the profits of the autotrader

## What have you done
During development of this project, we have come to realise that there is quite a lot of repeated and inefficient computation being done by our autotrader. Some of this inefficiency comes from repeated computation such as when we recalculate the mean and standard deviation each cycle of the autotrader. Another key area of inefficiency is our use of the Pandas library which is not necessarily best suited to our requirements. The decision was made to remove our dependency on the Pandas library for data storage and computation wherever possible with the aim of increasing the speed of our autotrader. Speed was highlighted as a key focus by Optiver since in real world financial markets the time periods that algorithmic trading has to deal with is very short. A few microseconds can be the difference between your trading system making a trade or the opportunity being missed. Due to this algorithmic trading firms will compete to have the shortest connection to an exchange and constantly look to improve the efficiency of their systems.

Our autotrader system is getting a new price value roughly every 1/10th of a second meaning over the course of a 15-minute trading simulation we are generating circa 9000 prices. These prices need to be stored to allow us to calculate the z_scores. Currently these prices are being stored in a Pandas series to which prices are concatenated iteratively. It is mentioned in the Pandas [API reference](https://pandas.pydata.org/docs/reference/api/pandas.concat.html) that due to the implementation of Series that it is not recommended to iteratively concatenate to a series. Which is what we have been doing each time a new price comes in. The suggested solution is to append values to a python array and then convert that list into a series when required. However, this solution would not be much better since every 1/10th of a second we would be converting a large python Array into a Pandas series.

Having had a look into the python [implementation of arrays](https://www.geeksforgeeks.org/internal-working-of-list-in-python/) I have learnt that they are implemented as a dynamic array. Where the allocated space in memory doubles each time, the array is filled. This is better than using a series however would become inefficient when appending to a full array. However, we only ever use the latest ETF and Future price value to calculate the latest z_score. This z_score is what is used for calculating the mean and standard deviation thatâ€™s required each time a new price comes in. We never actually use the raw price data again. So, there is no need to store historic price data for our autotrader. This is a major saving of memory and computation dealing the storage of a large amount of price values.
![stopped storing historical price data](/assets/images/stopped_recording_prices.png)<br>
We are no longer appending price values to an array or concatenating to a list. Now only the latest price is stored for both the ETF and Future.

Currently, each time a new price comes in we are recalculating the pair wise differences between ratio values and the mean of all the ratios and then dividing by the standard deviation which also requires us to calculate the sum pairwise differences between ratio values and the mean of ratio values. This is clearly inefficient and is meaning each cycle were repeating a lot of previous computation. The efficiency of the z_score calculation can be increased by breaking down the calculations carried out and storing sums as variables that we append to when new values come in. If we have a variable recording the sum of our ratios. It follows that we can calculate the mean of our ratios by dividing our ratios sum variable by the amount of ratio values. This is a much more efficient way of calculating mean as were no longer iteratively summing the ratios each cycle.

Now that we have an efficiently calculated mean we need to calculate the standard deviation to give us all the components to allow us to calculate the z_score that we are using for our buy and sell signals. Unfortunately, as the mean of our ratios is a live variable that will change throughout execution to calculate our standard deviation, we will have to recompute the difference between each ratio and the mean squared each cycle. To store the ratios, I have chosen to use a python array since it is well suited to append operations and when it is inefficient this is only for one cycle as we try to append to a full array and the array gets resized. This also avoids any swapping between arrays and series which we would have to do each cycle.

Finally, the z_score for the latest price can be calculated as usual from our new_ratio value minus the mean over the standard deviation. The efficiency improvements made mean the autotrader is now much faster and this has been seen by an increased profit. With the profit on dataset 2 when tested showing an increase of $219.80 and a total profit of $1281.00. This is because the autotrader can now deal with trades quicker meaning they are executed when the profit opportunity is greater.
![calculating z_score with greater efficiency](/assets/images/improved_calculations.png)

## What have you learnt
This final development stage has taught me much more about how python implement certain data structures and methods and how this compares to the implementations of modules such as Pandas and NumPy. For example, when looking into the best way to store the live price data and ratios there were pros and cons of using a python array and a Pandas series. A Pandas series took a lot of the mathematical computation out of our hands as the programmer but was not necessarily optimised for live data. Pandas has been optimised for analysis of large data sets that do not change in data type or size so was ideal for our initial jilter notebook work but then not suited for the live scenario. The python array is very good for appending live data thanks to its implementation as a dynamic array but falls down when the maximum size of the array is reached and the array resizes. So, for our scenario I chose to use a python array as its benefits outweighed the case for using a Pandas series. In order to learn more about the different data structures I was comparing, I read the official API / documentation that has been produced for the given data structure. This was where I initially came across the note that maybe Pandas series were not optimised for what we wanted and drove most of the development of this stage.

I learnt how it can sometimes be better to program custom solutions for common maths calculations based on the scenario. In our case we wanted to avoid the needless computation of recalculating values that we had calculated only moments ago. Splitting computation of sums and averages into their own variables meant previously done work could be kept and then added to each time we recalculated. This took a little bit of testing to make sure that our values were still the same. Which in our case they were give or take some rounding differences between python maths and Pandas. It was clear that sometimes taking the time to write custom made code will beat the built in functions of a module.

## Review of project
Across the learning-logs of this project we have created a working and consistently profitable autotrader. A key part of this project was getting to grips with commonly used data science modules such as Pandas. At the start of the project, I had virtually no proficiency in using these modules but now feel I am able to confidently program with them and understand their benefits and draw backs. There are still many areas of our trader that could be improved but the stage we are at now is a solid implementation of our strategy that has proved to be reliable. The project also got me interested in the world of automated high frequency trading and showed me that it was possible to create a primitive strategy using some understandable maths. I am happy with the autotrader that we produced and believe that we achieved the key goals we set out with at the start.